{
  "id": "entasis_engin_7",
  "title": "Entasis Engine - AI ëª¨ë¸ ì„¤ê³„",
  "content": "\n# ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ AI ëª¨ë¸ ì„¤ê³„\n\n## ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”\n\n### 1. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°\n\n#### 1.1 LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡\n\n```python\nclass PricePredictionLSTM(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_dim,\n            hidden_dim,\n            num_layers,\n            batch_first=True,\n            dropout=0.2\n        )\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        predictions = self.fc(lstm_out[:, -1, :])\n        return predictions\n```\n\n#### 1.2 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±\n\n```python\nclass EnsembleModel:\n    def __init__(self):\n        self.models = {\n            'lstm': PricePredictionLSTM(...),\n            'random_forest': RandomForestRegressor(...),\n            'xgboost': XGBRegressor(...),\n            'lightgbm': LGBMRegressor(...)\n        }\n        self.weights = {\n            'lstm': 0.4,\n            'random_forest': 0.2,\n            'xgboost': 0.2,\n            'lightgbm': 0.2\n        }\n```\n\n### 2. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§\n\n#### 2.1 ê¸°ìˆ ì  ì§€í‘œ\n\n```python\ndef calculate_technical_indicators(df):\n    # ì´ë™í‰ê· \n    df['sma_20'] = df['close'].rolling(window=20).mean()\n    df['sma_50'] = df['close'].rolling(window=50).mean()\n\n    # RSI\n    delta = df['close'].diff()\n    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n    df['rsi'] = 100 - (100 / (1 + gain/loss))\n\n    # MACD\n    exp1 = df['close'].ewm(span=12, adjust=False).mean()\n    exp2 = df['close'].ewm(span=26, adjust=False).mean()\n    df['macd'] = exp1 - exp2\n    df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n\n    return df\n```\n\n#### 2.2 ì‹œì¥ ê°ì„± ë¶„ì„\n\n```python\ndef analyze_market_sentiment(text_data):\n    sentiment_model = pipeline(\n        \"sentiment-analysis\",\n        model=\"finbert-sentiment\"\n    )\n    scores = sentiment_model(text_data)\n    return aggregate_sentiment_scores(scores)\n```\n\n## í•™ìŠµ íŒŒì´í”„ë¼ì¸\n\n### 1. ë°ì´í„° ì „ì²˜ë¦¬\n\n#### 1.1 ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„\n\n```python\ndef prepare_time_series(data, sequence_length):\n    sequences = []\n    targets = []\n\n    for i in range(len(data) - sequence_length):\n        seq = data[i:(i + sequence_length)]\n        target = data[i + sequence_length]\n        sequences.append(seq)\n        targets.append(target)\n\n    return np.array(sequences), np.array(targets)\n```\n\n#### 1.2 ë°ì´í„° ì •ê·œí™”\n\n```python\ndef normalize_features(data):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    return normalized_data, scaler\n```\n\n### 2. ëª¨ë¸ í•™ìŠµ\n\n#### 2.1 LSTM í•™ìŠµ í”„ë¡œì„¸ìŠ¤\n\n```python\ndef train_lstm_model(model, train_loader, val_loader, epochs):\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.MSELoss()\n\n    for epoch in range(epochs):\n        model.train()\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n\n        # ê²€ì¦\n        model.eval()\n        val_loss = validate_model(model, val_loader, criterion)\n        print(f'Epoch {epoch}: Val Loss = {val_loss:.4f}')\n```\n\n#### 2.2 ì•™ìƒë¸” ëª¨ë¸ í†µí•©\n\n```python\ndef ensemble_predict(models, weights, X):\n    predictions = []\n    for model_name, model in models.items():\n        pred = model.predict(X)\n        predictions.append(pred * weights[model_name])\n    return np.sum(predictions, axis=0)\n```\n\n## ğŸ“ˆ ì„±ëŠ¥ í‰ê°€\n\n### 1. í‰ê°€ ë©”íŠ¸ë¦­\n\n#### 1.1 ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€\n\n```python\ndef evaluate_predictions(y_true, y_pred):\n    metrics = {\n        'mse': mean_squared_error(y_true, y_pred),\n        'mae': mean_absolute_error(y_true, y_pred),\n        'r2': r2_score(y_true, y_pred),\n        'mape': mean_absolute_percentage_error(y_true, y_pred)\n    }\n    return metrics\n```\n\n#### 1.2 ë°±í…ŒìŠ¤íŒ…\n\n```python\ndef backtest_strategy(model, historical_data, initial_capital=10000):\n    portfolio = Portfolio(initial_capital)\n    signals = generate_trading_signals(model, historical_data)\n\n    for timestamp, signal in signals.items():\n        if signal > 0:\n            portfolio.long_position(timestamp)\n        elif signal < 0:\n            portfolio.short_position(timestamp)\n\n    return portfolio.calculate_returns()\n```\n\n## ë¦¬ìŠ¤í¬ ê´€ë¦¬\n\n### 1. ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§\n\n#### 1.1 Value at Risk (VaR) ê³„ì‚°\n\n```python\ndef calculate_var(returns, confidence_level=0.95):\n    return np.percentile(returns, (1 - confidence_level) * 100)\n```\n\n#### 1.2 Expected Shortfall\n\n```python\ndef calculate_expected_shortfall(returns, var):\n    return returns[returns <= var].mean()\n```\n\n### 2. í¬ì§€ì…˜ ì‚¬ì´ì§•\n\n```python\ndef calculate_position_size(prediction, confidence, account_size):\n    base_size = account_size * 0.02  # 2% ë¦¬ìŠ¤í¬ ë£°\n    adjusted_size = base_size * confidence\n    return min(adjusted_size, account_size * 0.05)  # ìµœëŒ€ 5% ì œí•œ\n```\n\n## ë°°í¬ ë° ëª¨ë‹ˆí„°ë§\n\n### 1. ëª¨ë¸ ì„œë¹™\n\n#### 1.1 ëª¨ë¸ ì§ë ¬í™”\n\n```python\ndef save_model(model, path):\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'hyperparameters': model.hyperparameters,\n        'scaler': model.scaler\n    }, path)\n```\n\n#### 1.2 ì‹¤ì‹œê°„ ì¶”ë¡ \n\n```python\n@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.json\n    prediction = model.predict(preprocess_data(data))\n    confidence = calculate_prediction_confidence(prediction)\n    return jsonify({\n        'prediction': prediction,\n        'confidence': confidence\n    })\n```\n\n### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\n\n```python\ndef monitor_model_performance(predictions, actuals):\n    metrics = calculate_metrics(predictions, actuals)\n    alert_if_degraded(metrics)\n    log_performance(metrics)\n```\n\nì´ ë¬¸ì„œëŠ” ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì„¤ê³„ ë° êµ¬í˜„ ìƒì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ë©°, ì„±ëŠ¥ ë©”íŠ¸ë¦­ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµë„ í•¨ê»˜ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.\n",
  "date": "2025-02-13T00:00:00+00:00",
  "category": "projects",
  "tags": [
    "ai",
    "machine-learning",
    "deep-learning",
    "lstm",
    "ensemble",
    "prediction",
    "risk-analysis"
  ],
  "thumbnail": null,
  "translations": {
    "ko": {
      "title": "Entasis Engine - AI ëª¨ë¸ ì„¤ê³„",
      "description": "",
      "content": "<h1 id=\"heading-0\">ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ AI ëª¨ë¸ ì„¤ê³„</h1>\n<h2 id=\"heading-1\">ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”</h2>\n<h3 id=\"heading-2\">1. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°</h3>\n<h4 id=\"heading-3\">1.1 LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡</h4>\n<pre><code class=\"language-python\">class PricePredictionLSTM(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_dim,\n            hidden_dim,\n            num_layers,\n            batch_first=True,\n            dropout=0.2\n        )\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        predictions = self.fc(lstm_out[:, -1, :])\n        return predictions\n</code></pre>\n<h4 id=\"heading-4\">1.2 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±</h4>\n<pre><code class=\"language-python\">class EnsembleModel:\n    def __init__(self):\n        self.models = {\n            'lstm': PricePredictionLSTM(...),\n            'random_forest': RandomForestRegressor(...),\n            'xgboost': XGBRegressor(...),\n            'lightgbm': LGBMRegressor(...)\n        }\n        self.weights = {\n            'lstm': 0.4,\n            'random_forest': 0.2,\n            'xgboost': 0.2,\n            'lightgbm': 0.2\n        }\n</code></pre>\n<h3 id=\"heading-5\">2. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§</h3>\n<h4 id=\"heading-6\">2.1 ê¸°ìˆ ì  ì§€í‘œ</h4>\n<pre><code class=\"language-python\">def calculate_technical_indicators(df):\n    # ì´ë™í‰ê· \n    df['sma_20'] = df['close'].rolling(window=20).mean()\n    df['sma_50'] = df['close'].rolling(window=50).mean()\n\n    # RSI\n    delta = df['close'].diff()\n    gain = (delta.where(delta &gt; 0, 0)).rolling(window=14).mean()\n    loss = (-delta.where(delta &lt; 0, 0)).rolling(window=14).mean()\n    df['rsi'] = 100 - (100 / (1 + gain/loss))\n\n    # MACD\n    exp1 = df['close'].ewm(span=12, adjust=False).mean()\n    exp2 = df['close'].ewm(span=26, adjust=False).mean()\n    df['macd'] = exp1 - exp2\n    df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n\n    return df\n</code></pre>\n<h4 id=\"heading-7\">2.2 ì‹œì¥ ê°ì„± ë¶„ì„</h4>\n<pre><code class=\"language-python\">def analyze_market_sentiment(text_data):\n    sentiment_model = pipeline(\n        \"sentiment-analysis\",\n        model=\"finbert-sentiment\"\n    )\n    scores = sentiment_model(text_data)\n    return aggregate_sentiment_scores(scores)\n</code></pre>\n<h2 id=\"heading-8\">í•™ìŠµ íŒŒì´í”„ë¼ì¸</h2>\n<h3 id=\"heading-9\">1. ë°ì´í„° ì „ì²˜ë¦¬</h3>\n<h4 id=\"heading-10\">1.1 ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„</h4>\n<pre><code class=\"language-python\">def prepare_time_series(data, sequence_length):\n    sequences = []\n    targets = []\n\n    for i in range(len(data) - sequence_length):\n        seq = data[i:(i + sequence_length)]\n        target = data[i + sequence_length]\n        sequences.append(seq)\n        targets.append(target)\n\n    return np.array(sequences), np.array(targets)\n</code></pre>\n<h4 id=\"heading-11\">1.2 ë°ì´í„° ì •ê·œí™”</h4>\n<pre><code class=\"language-python\">def normalize_features(data):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    return normalized_data, scaler\n</code></pre>\n<h3 id=\"heading-12\">2. ëª¨ë¸ í•™ìŠµ</h3>\n<h4 id=\"heading-13\">2.1 LSTM í•™ìŠµ í”„ë¡œì„¸ìŠ¤</h4>\n<pre><code class=\"language-python\">def train_lstm_model(model, train_loader, val_loader, epochs):\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.MSELoss()\n\n    for epoch in range(epochs):\n        model.train()\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n\n        # ê²€ì¦\n        model.eval()\n        val_loss = validate_model(model, val_loader, criterion)\n        print(f'Epoch {epoch}: Val Loss = {val_loss:.4f}')\n</code></pre>\n<h4 id=\"heading-14\">2.2 ì•™ìƒë¸” ëª¨ë¸ í†µí•©</h4>\n<pre><code class=\"language-python\">def ensemble_predict(models, weights, X):\n    predictions = []\n    for model_name, model in models.items():\n        pred = model.predict(X)\n        predictions.append(pred * weights[model_name])\n    return np.sum(predictions, axis=0)\n</code></pre>\n<h2 id=\"heading-15\">ğŸ“ˆ ì„±ëŠ¥ í‰ê°€</h2>\n<h3 id=\"heading-16\">1. í‰ê°€ ë©”íŠ¸ë¦­</h3>\n<h4 id=\"heading-17\">1.1 ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€</h4>\n<pre><code class=\"language-python\">def evaluate_predictions(y_true, y_pred):\n    metrics = {\n        'mse': mean_squared_error(y_true, y_pred),\n        'mae': mean_absolute_error(y_true, y_pred),\n        'r2': r2_score(y_true, y_pred),\n        'mape': mean_absolute_percentage_error(y_true, y_pred)\n    }\n    return metrics\n</code></pre>\n<h4 id=\"heading-18\">1.2 ë°±í…ŒìŠ¤íŒ…</h4>\n<pre><code class=\"language-python\">def backtest_strategy(model, historical_data, initial_capital=10000):\n    portfolio = Portfolio(initial_capital)\n    signals = generate_trading_signals(model, historical_data)\n\n    for timestamp, signal in signals.items():\n        if signal &gt; 0:\n            portfolio.long_position(timestamp)\n        elif signal &lt; 0:\n            portfolio.short_position(timestamp)\n\n    return portfolio.calculate_returns()\n</code></pre>\n<h2 id=\"heading-19\">ë¦¬ìŠ¤í¬ ê´€ë¦¬</h2>\n<h3 id=\"heading-20\">1. ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§</h3>\n<h4 id=\"heading-21\">1.1 Value at Risk (VaR) ê³„ì‚°</h4>\n<pre><code class=\"language-python\">def calculate_var(returns, confidence_level=0.95):\n    return np.percentile(returns, (1 - confidence_level) * 100)\n</code></pre>\n<h4 id=\"heading-22\">1.2 Expected Shortfall</h4>\n<pre><code class=\"language-python\">def calculate_expected_shortfall(returns, var):\n    return returns[returns &lt;= var].mean()\n</code></pre>\n<h3 id=\"heading-23\">2. í¬ì§€ì…˜ ì‚¬ì´ì§•</h3>\n<pre><code class=\"language-python\">def calculate_position_size(prediction, confidence, account_size):\n    base_size = account_size * 0.02  # 2% ë¦¬ìŠ¤í¬ ë£°\n    adjusted_size = base_size * confidence\n    return min(adjusted_size, account_size * 0.05)  # ìµœëŒ€ 5% ì œí•œ\n</code></pre>\n<h2 id=\"heading-24\">ğŸš€ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§</h2>\n<h3 id=\"heading-25\">1. ëª¨ë¸ ì„œë¹™</h3>\n<h4 id=\"heading-26\">1.1 ëª¨ë¸ ì§ë ¬í™”</h4>\n<pre><code class=\"language-python\">def save_model(model, path):\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'hyperparameters': model.hyperparameters,\n        'scaler': model.scaler\n    }, path)\n</code></pre>\n<h4 id=\"heading-27\">1.2 ì‹¤ì‹œê°„ ì¶”ë¡ </h4>\n<pre><code class=\"language-python\">@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.json\n    prediction = model.predict(preprocess_data(data))\n    confidence = calculate_prediction_confidence(prediction)\n    return jsonify({\n        'prediction': prediction,\n        'confidence': confidence\n    })\n</code></pre>\n<h3 id=\"heading-28\">2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§</h3>\n<pre><code class=\"language-python\">def monitor_model_performance(predictions, actuals):\n    metrics = calculate_metrics(predictions, actuals)\n    alert_if_degraded(metrics)\n    log_performance(metrics)\n</code></pre>\n<p>ì´ ë¬¸ì„œëŠ” ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì„¤ê³„ ë° êµ¬í˜„ ìƒì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ë©°, ì„±ëŠ¥ ë©”íŠ¸ë¦­ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµë„ í•¨ê»˜ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.</p>\n",
      "tocItems": [
        {
          "id": "heading-0",
          "text": "ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ AI ëª¨ë¸ ì„¤ê³„",
          "level": 1,
          "isMainTopic": true,
          "position": 0
        },
        {
          "id": "heading-1",
          "text": "ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”",
          "level": 2,
          "isMainTopic": true,
          "position": 50
        },
        {
          "id": "heading-2",
          "text": "1. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°",
          "level": 3,
          "isMainTopic": false,
          "position": 100
        },
        {
          "id": "heading-3",
          "text": "1.1 LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡",
          "level": 4,
          "isMainTopic": false,
          "position": 150
        },
        {
          "id": "heading-4",
          "text": "1.2 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±",
          "level": 4,
          "isMainTopic": false,
          "position": 200
        },
        {
          "id": "heading-5",
          "text": "2. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§",
          "level": 3,
          "isMainTopic": false,
          "position": 250
        },
        {
          "id": "heading-6",
          "text": "2.1 ê¸°ìˆ ì  ì§€í‘œ",
          "level": 4,
          "isMainTopic": false,
          "position": 300
        },
        {
          "id": "heading-7",
          "text": "2.2 ì‹œì¥ ê°ì„± ë¶„ì„",
          "level": 4,
          "isMainTopic": false,
          "position": 350
        },
        {
          "id": "heading-8",
          "text": "í•™ìŠµ íŒŒì´í”„ë¼ì¸",
          "level": 2,
          "isMainTopic": true,
          "position": 400
        },
        {
          "id": "heading-9",
          "text": "1. ë°ì´í„° ì „ì²˜ë¦¬",
          "level": 3,
          "isMainTopic": false,
          "position": 450
        },
        {
          "id": "heading-10",
          "text": "1.1 ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„",
          "level": 4,
          "isMainTopic": false,
          "position": 500
        },
        {
          "id": "heading-11",
          "text": "1.2 ë°ì´í„° ì •ê·œí™”",
          "level": 4,
          "isMainTopic": false,
          "position": 550
        },
        {
          "id": "heading-12",
          "text": "2. ëª¨ë¸ í•™ìŠµ",
          "level": 3,
          "isMainTopic": false,
          "position": 600
        },
        {
          "id": "heading-13",
          "text": "2.1 LSTM í•™ìŠµ í”„ë¡œì„¸ìŠ¤",
          "level": 4,
          "isMainTopic": false,
          "position": 650
        },
        {
          "id": "heading-14",
          "text": "2.2 ì•™ìƒë¸” ëª¨ë¸ í†µí•©",
          "level": 4,
          "isMainTopic": false,
          "position": 700
        },
        {
          "id": "heading-15",
          "text": "ğŸ“ˆ ì„±ëŠ¥ í‰ê°€",
          "level": 2,
          "isMainTopic": true,
          "position": 750
        },
        {
          "id": "heading-16",
          "text": "1. í‰ê°€ ë©”íŠ¸ë¦­",
          "level": 3,
          "isMainTopic": false,
          "position": 800
        },
        {
          "id": "heading-17",
          "text": "1.1 ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€",
          "level": 4,
          "isMainTopic": false,
          "position": 850
        },
        {
          "id": "heading-18",
          "text": "1.2 ë°±í…ŒìŠ¤íŒ…",
          "level": 4,
          "isMainTopic": false,
          "position": 900
        },
        {
          "id": "heading-19",
          "text": "ë¦¬ìŠ¤í¬ ê´€ë¦¬",
          "level": 2,
          "isMainTopic": true,
          "position": 950
        },
        {
          "id": "heading-20",
          "text": "1. ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§",
          "level": 3,
          "isMainTopic": false,
          "position": 1000
        },
        {
          "id": "heading-21",
          "text": "1.1 Value at Risk (VaR) ê³„ì‚°",
          "level": 4,
          "isMainTopic": false,
          "position": 1050
        },
        {
          "id": "heading-22",
          "text": "1.2 Expected Shortfall",
          "level": 4,
          "isMainTopic": false,
          "position": 1100
        },
        {
          "id": "heading-23",
          "text": "2. í¬ì§€ì…˜ ì‚¬ì´ì§•",
          "level": 3,
          "isMainTopic": false,
          "position": 1150
        },
        {
          "id": "heading-24",
          "text": "ğŸš€ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§",
          "level": 2,
          "isMainTopic": true,
          "position": 1200
        },
        {
          "id": "heading-25",
          "text": "1. ëª¨ë¸ ì„œë¹™",
          "level": 3,
          "isMainTopic": false,
          "position": 1250
        },
        {
          "id": "heading-26",
          "text": "1.1 ëª¨ë¸ ì§ë ¬í™”",
          "level": 4,
          "isMainTopic": false,
          "position": 1300
        },
        {
          "id": "heading-27",
          "text": "1.2 ì‹¤ì‹œê°„ ì¶”ë¡ ",
          "level": 4,
          "isMainTopic": false,
          "position": 1350
        },
        {
          "id": "heading-28",
          "text": "2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
          "level": 3,
          "isMainTopic": false,
          "position": 1400
        }
      ]
    },
    "en": {
      "title": "Entasis Engine - AI Model Design",
      "description": "",
      "content": "<h1 id=\"heading-0\">Financial Data Analysis System AI Model Design</h1>\n<h2 id=\"heading-1\">Model Architecture Overview</h2>\n<h3 id=\"heading-2\">1. Prediction Model Structure</h3>\n<h4 id=\"heading-3\">1.1 LSTM-based Time Series Prediction</h4>\n<pre><code class=\"language-python\">class PricePredictionLSTM(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_dim,\n            hidden_dim,\n            num_layers,\n            batch_first=True,\n            dropout=0.2\n        )\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        lstm_out, _ = self.lstm(x)\n        predictions = self.fc(lstm_out[:, -1, :])\n        return predictions\n</code></pre>\n<h4 id=\"heading-4\">1.2 Ensemble Model Configuration</h4>\n<pre><code class=\"language-python\">class EnsembleModel:\n    def __init__(self):\n        self.models = {\n            'lstm': PricePredictionLSTM(...),\n            'random_forest': RandomForestRegressor(...),\n            'xgboost': XGBRegressor(...),\n            'lightgbm': LGBMRegressor(...)\n        }\n        self.weights = {\n            'lstm': 0.4,\n            'random_forest': 0.2,\n            'xgboost': 0.2,\n            'lightgbm': 0.2\n        }\n</code></pre>\n<h3 id=\"heading-5\">2. Feature Engineering</h3>\n<h4 id=\"heading-6\">2.1 Technical Indicators</h4>\n<pre><code class=\"language-python\">def calculate_technical_indicators(df):\n    # Moving average\n    df['sma_20'] = df['close'].rolling(window=20).mean()\n    df['sma_50'] = df['close'].rolling(window=50).mean()\n\n    # RSI\n    delta = df['close'].diff()\n    gain = (delta.where(delta &gt; 0, 0)).rolling(window=14).mean()\n    loss = (-delta.where(delta &lt; 0, 0)).rolling(window=14).mean()\n    df['rsi'] = 100 - (100 / (1 + gain/loss))\n\n    # MACD\n    exp1 = df['close'].ewm(span=12, adjust=False).mean()\n    exp2 = df['close'].ewm(span=26, adjust=False).mean()\n    df['macd'] = exp1 - exp2\n    df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n\n    return df\n</code></pre>\n<h4 id=\"heading-7\">2.2 Market Sentiment Analysis</h4>\n<pre><code class=\"language-python\">def analyze_market_sentiment(text_data):\n    sentiment_model = pipeline(\n        \"sentiment-analysis\",\n        model=\"finbert-sentiment\"\n    )\n    scores = sentiment_model(text_data)\n    return aggregate_sentiment_scores(scores)\n</code></pre>\n<h2 id=\"heading-8\">Learning Pipeline</h2>\n<h3 id=\"heading-9\">1. Data Preprocessing</h3>\n<h4 id=\"heading-10\">1.1 Time Series Data Preparation</h4>\n<pre><code class=\"language-python\">def prepare_time_series(data, sequence_length):\n    sequences = []\n    targets = []\n\n    for i in range(len(data) - sequence_length):\n        seq = data[i:(i + sequence_length)]\n        target = data[i + sequence_length]\n        sequences.append(seq)\n        targets.append(target)\n\n    return np.array(sequences), np.array(targets)\n</code></pre>\n<h4 id=\"heading-11\">1.2 Data Normalization</h4>\n<pre><code class=\"language-python\">def normalize_features(data):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    return normalized_data, scaler\n</code></pre>\n<h3 id=\"heading-12\">2. Model Training</h3>\n<h4 id=\"heading-13\">2.1 LSTM Training Process</h4>\n<pre><code class=\"language-python\">def train_lstm_model(model, train_loader, val_loader, epochs):\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.MSELoss()\n\n    for epoch in range(epochs):\n        model.train()\n        for batch_X, batch_y in train_loader:\n            optimizer.zero_grad()\n            outputs = model(batch_X)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n\n        # Validation\n        model.eval()\n        val_loss = validate_model(model, val_loader, criterion)\n        print(f'Epoch {epoch}: Val Loss = {val_loss:.4f}')\n</code></pre>\n<h4 id=\"heading-14\">2.2 Ensemble Model Integration</h4>\n<pre><code class=\"language-python\">def ensemble_predict(models, weights, X):\n    predictions = []\n    for model_name, model in models.items():\n        pred = model.predict(X)\n        predictions.append(pred * weights[model_name])\n    return np.sum(predictions, axis=0)\n</code></pre>\n<h2 id=\"heading-15\">ğŸ“ˆ Performance Evaluation</h2>\n<h3 id=\"heading-16\">1. Evaluation Metrics</h3>\n<h4 id=\"heading-17\">1.1 Prediction Accuracy Evaluation</h4>\n<pre><code class=\"language-python\">def evaluate_predictions(y_true, y_pred):\n    metrics = {\n        'mse': mean_squared_error(y_true, y_pred),\n        'mae': mean_absolute_error(y_true, y_pred),\n        'r2': r2_score(y_true, y_pred),\n        'mape': mean_absolute_percentage_error(y_true, y_pred)\n    }\n    return metrics\n</code></pre>\n<h4 id=\"heading-18\">1.2 Backtesting</h4>\n<pre><code class=\"language-python\">def backtest_strategy(model, historical_data, initial_capital=10000):\n    portfolio = Portfolio(initial_capital)\n    signals = generate_trading_signals(model, historical_data)\n\n    for timestamp, signal in signals.items():\n        if signal &gt; 0:\n            portfolio.long_position(timestamp)\n        elif signal &lt; 0:\n            portfolio.short_position(timestamp)\n\n    return portfolio.calculate_returns()\n</code></pre>\n<h2 id=\"heading-19\">Risk Management</h2>\n<h3 id=\"heading-20\">1. Risk Monitoring</h3>\n<h4 id=\"heading-21\">1.1 Value at Risk (VaR) Calculation</h4>\n<pre><code class=\"language-python\">def calculate_var(returns, confidence_level=0.95):\n    return np.percentile(returns, (1 - confidence_level) * 100)\n</code></pre>\n<h4 id=\"heading-22\">1.2 Expected Shortfall</h4>\n<pre><code class=\"language-python\">def calculate_expected_shortfall(returns, var):\n    return returns[returns &lt;= var].mean()\n</code></pre>\n<h3 id=\"heading-23\">2. Position Sizing</h3>\n<pre><code class=\"language-python\">def calculate_position_size(prediction, confidence, account_size):\n    base_size = account_size * 0.02  # 2% risk rule\n    adjusted_size = base_size * confidence\n    return min(adjusted_size, account_size * 0.05)  # Maximum 5% limit\n</code></pre>\n<h2 id=\"heading-24\">ğŸš€ Deployment &amp; Monitoring</h2>\n<h3 id=\"heading-25\">1. Model Serving</h3>\n<h4 id=\"heading-26\">1.1 Model Serialization</h4>\n<pre><code class=\"language-python\">def save_model(model, path):\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'hyperparameters': model.hyperparameters,\n        'scaler': model.scaler\n    }, path)\n</code></pre>\n<h4 id=\"heading-27\">1.2 Real-time Inference</h4>\n<pre><code class=\"language-python\">@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.json\n    prediction = model.predict(preprocess_data(data))\n    confidence = calculate_prediction_confidence(prediction)\n    return jsonify({\n        'prediction': prediction,\n        'confidence': confidence\n    })\n</code></pre>\n<h3 id=\"heading-28\">2. Performance Monitoring</h3>\n<pre><code class=\"language-python\">def monitor_model_performance(predictions, actuals):\n    metrics = calculate_metrics(predictions, actuals)\n    alert_if_degraded(metrics)\n    log_performance(metrics)\n</code></pre>\n<p>This document provides the AI model design and implementation details for the financial data analysis system. The model is continuously improved, and the performance metrics and risk management strategies are also updated.</p>\n",
      "tocItems": [
        {
          "id": "heading-0",
          "text": "Financial Data Analysis System AI Model Design",
          "level": 1,
          "isMainTopic": true,
          "position": 0
        },
        {
          "id": "heading-1",
          "text": "Model Architecture Overview",
          "level": 2,
          "isMainTopic": true,
          "position": 50
        },
        {
          "id": "heading-2",
          "text": "1. Prediction Model Structure",
          "level": 3,
          "isMainTopic": false,
          "position": 100
        },
        {
          "id": "heading-3",
          "text": "1.1 LSTM-based Time Series Prediction",
          "level": 4,
          "isMainTopic": false,
          "position": 150
        },
        {
          "id": "heading-4",
          "text": "1.2 Ensemble Model Configuration",
          "level": 4,
          "isMainTopic": false,
          "position": 200
        },
        {
          "id": "heading-5",
          "text": "2. Feature Engineering",
          "level": 3,
          "isMainTopic": false,
          "position": 250
        },
        {
          "id": "heading-6",
          "text": "2.1 Technical Indicators",
          "level": 4,
          "isMainTopic": false,
          "position": 300
        },
        {
          "id": "heading-7",
          "text": "2.2 Market Sentiment Analysis",
          "level": 4,
          "isMainTopic": false,
          "position": 350
        },
        {
          "id": "heading-8",
          "text": "Learning Pipeline",
          "level": 2,
          "isMainTopic": true,
          "position": 400
        },
        {
          "id": "heading-9",
          "text": "1. Data Preprocessing",
          "level": 3,
          "isMainTopic": false,
          "position": 450
        },
        {
          "id": "heading-10",
          "text": "1.1 Time Series Data Preparation",
          "level": 4,
          "isMainTopic": false,
          "position": 500
        },
        {
          "id": "heading-11",
          "text": "1.2 Data Normalization",
          "level": 4,
          "isMainTopic": false,
          "position": 550
        },
        {
          "id": "heading-12",
          "text": "2. Model Training",
          "level": 3,
          "isMainTopic": false,
          "position": 600
        },
        {
          "id": "heading-13",
          "text": "2.1 LSTM Training Process",
          "level": 4,
          "isMainTopic": false,
          "position": 650
        },
        {
          "id": "heading-14",
          "text": "2.2 Ensemble Model Integration",
          "level": 4,
          "isMainTopic": false,
          "position": 700
        },
        {
          "id": "heading-15",
          "text": "ğŸ“ˆ Performance Evaluation",
          "level": 2,
          "isMainTopic": true,
          "position": 750
        },
        {
          "id": "heading-16",
          "text": "1. Evaluation Metrics",
          "level": 3,
          "isMainTopic": false,
          "position": 800
        },
        {
          "id": "heading-17",
          "text": "1.1 Prediction Accuracy Evaluation",
          "level": 4,
          "isMainTopic": false,
          "position": 850
        },
        {
          "id": "heading-18",
          "text": "1.2 Backtesting",
          "level": 4,
          "isMainTopic": false,
          "position": 900
        },
        {
          "id": "heading-19",
          "text": "Risk Management",
          "level": 2,
          "isMainTopic": true,
          "position": 950
        },
        {
          "id": "heading-20",
          "text": "1. Risk Monitoring",
          "level": 3,
          "isMainTopic": false,
          "position": 1000
        },
        {
          "id": "heading-21",
          "text": "1.1 Value at Risk (VaR) Calculation",
          "level": 4,
          "isMainTopic": false,
          "position": 1050
        },
        {
          "id": "heading-22",
          "text": "1.2 Expected Shortfall",
          "level": 4,
          "isMainTopic": false,
          "position": 1100
        },
        {
          "id": "heading-23",
          "text": "2. Position Sizing",
          "level": 3,
          "isMainTopic": false,
          "position": 1150
        },
        {
          "id": "heading-24",
          "text": "ğŸš€ Deployment & Monitoring",
          "level": 2,
          "isMainTopic": true,
          "position": 1200
        },
        {
          "id": "heading-25",
          "text": "1. Model Serving",
          "level": 3,
          "isMainTopic": false,
          "position": 1250
        },
        {
          "id": "heading-26",
          "text": "1.1 Model Serialization",
          "level": 4,
          "isMainTopic": false,
          "position": 1300
        },
        {
          "id": "heading-27",
          "text": "1.2 Real-time Inference",
          "level": 4,
          "isMainTopic": false,
          "position": 1350
        },
        {
          "id": "heading-28",
          "text": "2. Performance Monitoring",
          "level": 3,
          "isMainTopic": false,
          "position": 1400
        }
      ]
    }
  },
  "imageHeights": {}
}