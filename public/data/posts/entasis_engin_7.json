{
  "id": "entasis_engin_7",
  "title": "Entasis Engine - AI ëª¨ë¸ ì„¤ê³„",
  "content": "\r\n# ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ AI ëª¨ë¸ ì„¤ê³„\r\n\r\n## ğŸ“Š ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”\r\n\r\n### 1. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°\r\n\r\n#### 1.1 LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡\r\n\r\n```python\r\nclass PricePredictionLSTM(nn.Module):\r\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\r\n        super().__init__()\r\n        self.lstm = nn.LSTM(\r\n            input_dim,\r\n            hidden_dim,\r\n            num_layers,\r\n            batch_first=True,\r\n            dropout=0.2\r\n        )\r\n        self.fc = nn.Linear(hidden_dim, output_dim)\r\n\r\n    def forward(self, x):\r\n        lstm_out, _ = self.lstm(x)\r\n        predictions = self.fc(lstm_out[:, -1, :])\r\n        return predictions\r\n```\r\n\r\n#### 1.2 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±\r\n\r\n```python\r\nclass EnsembleModel:\r\n    def __init__(self):\r\n        self.models = {\r\n            'lstm': PricePredictionLSTM(...),\r\n            'random_forest': RandomForestRegressor(...),\r\n            'xgboost': XGBRegressor(...),\r\n            'lightgbm': LGBMRegressor(...)\r\n        }\r\n        self.weights = {\r\n            'lstm': 0.4,\r\n            'random_forest': 0.2,\r\n            'xgboost': 0.2,\r\n            'lightgbm': 0.2\r\n        }\r\n```\r\n\r\n### 2. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§\r\n\r\n#### 2.1 ê¸°ìˆ ì  ì§€í‘œ\r\n\r\n```python\r\ndef calculate_technical_indicators(df):\r\n    # ì´ë™í‰ê· \r\n    df['sma_20'] = df['close'].rolling(window=20).mean()\r\n    df['sma_50'] = df['close'].rolling(window=50).mean()\r\n\r\n    # RSI\r\n    delta = df['close'].diff()\r\n    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\r\n    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\r\n    df['rsi'] = 100 - (100 / (1 + gain/loss))\r\n\r\n    # MACD\r\n    exp1 = df['close'].ewm(span=12, adjust=False).mean()\r\n    exp2 = df['close'].ewm(span=26, adjust=False).mean()\r\n    df['macd'] = exp1 - exp2\r\n    df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()\r\n\r\n    return df\r\n```\r\n\r\n#### 2.2 ì‹œì¥ ê°ì„± ë¶„ì„\r\n\r\n```python\r\ndef analyze_market_sentiment(text_data):\r\n    sentiment_model = pipeline(\r\n        \"sentiment-analysis\",\r\n        model=\"finbert-sentiment\"\r\n    )\r\n    scores = sentiment_model(text_data)\r\n    return aggregate_sentiment_scores(scores)\r\n```\r\n\r\n## ğŸ”„ í•™ìŠµ íŒŒì´í”„ë¼ì¸\r\n\r\n### 1. ë°ì´í„° ì „ì²˜ë¦¬\r\n\r\n#### 1.1 ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„\r\n\r\n```python\r\ndef prepare_time_series(data, sequence_length):\r\n    sequences = []\r\n    targets = []\r\n\r\n    for i in range(len(data) - sequence_length):\r\n        seq = data[i:(i + sequence_length)]\r\n        target = data[i + sequence_length]\r\n        sequences.append(seq)\r\n        targets.append(target)\r\n\r\n    return np.array(sequences), np.array(targets)\r\n```\r\n\r\n#### 1.2 ë°ì´í„° ì •ê·œí™”\r\n\r\n```python\r\ndef normalize_features(data):\r\n    scaler = MinMaxScaler()\r\n    normalized_data = scaler.fit_transform(data)\r\n    return normalized_data, scaler\r\n```\r\n\r\n### 2. ëª¨ë¸ í•™ìŠµ\r\n\r\n#### 2.1 LSTM í•™ìŠµ í”„ë¡œì„¸ìŠ¤\r\n\r\n```python\r\ndef train_lstm_model(model, train_loader, val_loader, epochs):\r\n    optimizer = optim.Adam(model.parameters())\r\n    criterion = nn.MSELoss()\r\n\r\n    for epoch in range(epochs):\r\n        model.train()\r\n        for batch_X, batch_y in train_loader:\r\n            optimizer.zero_grad()\r\n            outputs = model(batch_X)\r\n            loss = criterion(outputs, batch_y)\r\n            loss.backward()\r\n            optimizer.step()\r\n\r\n        # ê²€ì¦\r\n        model.eval()\r\n        val_loss = validate_model(model, val_loader, criterion)\r\n        print(f'Epoch {epoch}: Val Loss = {val_loss:.4f}')\r\n```\r\n\r\n#### 2.2 ì•™ìƒë¸” ëª¨ë¸ í†µí•©\r\n\r\n```python\r\ndef ensemble_predict(models, weights, X):\r\n    predictions = []\r\n    for model_name, model in models.items():\r\n        pred = model.predict(X)\r\n        predictions.append(pred * weights[model_name])\r\n    return np.sum(predictions, axis=0)\r\n```\r\n\r\n## ğŸ“ˆ ì„±ëŠ¥ í‰ê°€\r\n\r\n### 1. í‰ê°€ ë©”íŠ¸ë¦­\r\n\r\n#### 1.1 ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€\r\n\r\n```python\r\ndef evaluate_predictions(y_true, y_pred):\r\n    metrics = {\r\n        'mse': mean_squared_error(y_true, y_pred),\r\n        'mae': mean_absolute_error(y_true, y_pred),\r\n        'r2': r2_score(y_true, y_pred),\r\n        'mape': mean_absolute_percentage_error(y_true, y_pred)\r\n    }\r\n    return metrics\r\n```\r\n\r\n#### 1.2 ë°±í…ŒìŠ¤íŒ…\r\n\r\n```python\r\ndef backtest_strategy(model, historical_data, initial_capital=10000):\r\n    portfolio = Portfolio(initial_capital)\r\n    signals = generate_trading_signals(model, historical_data)\r\n\r\n    for timestamp, signal in signals.items():\r\n        if signal > 0:\r\n            portfolio.long_position(timestamp)\r\n        elif signal < 0:\r\n            portfolio.short_position(timestamp)\r\n\r\n    return portfolio.calculate_returns()\r\n```\r\n\r\n## ğŸ” ë¦¬ìŠ¤í¬ ê´€ë¦¬\r\n\r\n### 1. ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§\r\n\r\n#### 1.1 Value at Risk (VaR) ê³„ì‚°\r\n\r\n```python\r\ndef calculate_var(returns, confidence_level=0.95):\r\n    return np.percentile(returns, (1 - confidence_level) * 100)\r\n```\r\n\r\n#### 1.2 Expected Shortfall\r\n\r\n```python\r\ndef calculate_expected_shortfall(returns, var):\r\n    return returns[returns <= var].mean()\r\n```\r\n\r\n### 2. í¬ì§€ì…˜ ì‚¬ì´ì§•\r\n\r\n```python\r\ndef calculate_position_size(prediction, confidence, account_size):\r\n    base_size = account_size * 0.02  # 2% ë¦¬ìŠ¤í¬ ë£°\r\n    adjusted_size = base_size * confidence\r\n    return min(adjusted_size, account_size * 0.05)  # ìµœëŒ€ 5% ì œí•œ\r\n```\r\n\r\n## ğŸš€ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§\r\n\r\n### 1. ëª¨ë¸ ì„œë¹™\r\n\r\n#### 1.1 ëª¨ë¸ ì§ë ¬í™”\r\n\r\n```python\r\ndef save_model(model, path):\r\n    torch.save({\r\n        'model_state_dict': model.state_dict(),\r\n        'hyperparameters': model.hyperparameters,\r\n        'scaler': model.scaler\r\n    }, path)\r\n```\r\n\r\n#### 1.2 ì‹¤ì‹œê°„ ì¶”ë¡ \r\n\r\n```python\r\n@app.route('/predict', methods=['POST'])\r\ndef predict():\r\n    data = request.json\r\n    prediction = model.predict(preprocess_data(data))\r\n    confidence = calculate_prediction_confidence(prediction)\r\n    return jsonify({\r\n        'prediction': prediction,\r\n        'confidence': confidence\r\n    })\r\n```\r\n\r\n### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§\r\n\r\n```python\r\ndef monitor_model_performance(predictions, actuals):\r\n    metrics = calculate_metrics(predictions, actuals)\r\n    alert_if_degraded(metrics)\r\n    log_performance(metrics)\r\n```\r\n\r\nì´ ë¬¸ì„œëŠ” ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì„¤ê³„ ë° êµ¬í˜„ ìƒì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ë©°, ì„±ëŠ¥ ë©”íŠ¸ë¦­ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµë„ í•¨ê»˜ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. ğŸš€\r\n",
  "date": "2025-02-13",
  "category": "projects",
  "tags": [
    "ai",
    "machine-learning",
    "deep-learning",
    "lstm",
    "ensemble",
    "prediction",
    "risk-analysis"
  ],
  "thumbnail": "/images/cryptocurrency.jpg",
  "translations": {
    "ko": {
      "title": "Entasis Engine - AI ëª¨ë¸ ì„¤ê³„",
      "description": "ê°€ìƒìì‚° ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° êµ¬í˜„ ìƒì„¸",
      "content": "<hr>\n<h2 id=\"heading-0\">title: \"Entasis Engine - AI ëª¨ë¸ ì„¤ê³„\"\ndate: \"2025-02-13\"\ncategory: \"projects\"\ndescription: \"ê°€ìƒìì‚° ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° êµ¬í˜„ ìƒì„¸\"\ntags:\n[\n\"ai\",\n\"machine-learning\",\n\"deep-learning\",\n\"lstm\",\n\"ensemble\",\n\"prediction\",\n\"risk-analysis\",\n]\nthumbnail: \"/images/cryptocurrency.jpg\"</h2>\n<h1 id=\"heading-1\">ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ AI ëª¨ë¸ ì„¤ê³„</h1>\n<h2 id=\"heading-2\">ğŸ“Š ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”</h2>\n<h3 id=\"heading-3\">1. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°</h3>\n<h4 id=\"heading-4\">1.1 LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡</h4>\n<pre><code class=\"language-python\">class PricePredictionLSTM(nn.Module):\n    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n        super().__init__()\n        self.lstm = nn.LSTM(\n            input_dim,\n            hidden_dim,\n            num_layers,\n            batch_first=True,\n            dropout=0.2\n        )\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n<pre><code>def forward(self, x):\n    lstm_out, _ = self.lstm(x)\n    predictions = self.fc(lstm_out[:, -1, :])\n    return predictions\n</code></pre>\n</code><p><code class=\"language-python\"></code></p></pre><p></p><h4 id=\"heading-5\">1.2 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±</h4>\n<pre><code class=\"language-python\">class EnsembleModel:\n    def __init__(self):\n        self.models = {\n            'lstm': PricePredictionLSTM(...),\n            'random_forest': RandomForestRegressor(...),\n            'xgboost': XGBRegressor(...),\n            'lightgbm': LGBMRegressor(...)\n        }\n        self.weights = {\n            'lstm': 0.4,\n            'random_forest': 0.2,\n            'xgboost': 0.2,\n            'lightgbm': 0.2\n        }\n</code></pre>\n<h3 id=\"heading-6\">2. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§</h3>\n<h4 id=\"heading-7\">2.1 ê¸°ìˆ ì  ì§€í‘œ</h4>\n<pre><code class=\"language-python\">def calculate_technical_indicators(df):\n    # ì´ë™í‰ê· \n    df['sma_20'] = df['close'].rolling(window=20).mean()\n    df['sma_50'] = df['close'].rolling(window=50).mean()\n\n<pre><code># RSI\ndelta = df['close'].diff()\ngain = (delta.where(delta &gt; 0, 0)).rolling(window=14).mean()\nloss = (-delta.where(delta &amp;#x3C; 0, 0)).rolling(window=14).mean()\ndf['rsi'] = 100 - (100 / (1 + gain/loss))\n\n# MACD\nexp1 = df['close'].ewm(span=12, adjust=False).mean()\nexp2 = df['close'].ewm(span=26, adjust=False).mean()\ndf['macd'] = exp1 - exp2\ndf['signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n\nreturn df\n</code></pre>\n</code><p><code class=\"language-python\"></code></p></pre><p></p><h4 id=\"heading-8\">2.2 ì‹œì¥ ê°ì„± ë¶„ì„</h4>\n<pre><code class=\"language-python\">def analyze_market_sentiment(text_data):\n    sentiment_model = pipeline(\n        \"sentiment-analysis\",\n        model=\"finbert-sentiment\"\n    )\n    scores = sentiment_model(text_data)\n    return aggregate_sentiment_scores(scores)\n</code></pre>\n<h2 id=\"heading-9\">ğŸ”„ í•™ìŠµ íŒŒì´í”„ë¼ì¸</h2>\n<h3 id=\"heading-10\">1. ë°ì´í„° ì „ì²˜ë¦¬</h3>\n<h4 id=\"heading-11\">1.1 ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„</h4>\n<pre><code class=\"language-python\">def prepare_time_series(data, sequence_length):\n    sequences = []\n    targets = []\n\n<pre><code>for i in range(len(data) - sequence_length):\n    seq = data[i:(i + sequence_length)]\n    target = data[i + sequence_length]\n    sequences.append(seq)\n    targets.append(target)\n\nreturn np.array(sequences), np.array(targets)\n</code></pre>\n</code><p><code class=\"language-python\"></code></p></pre><p></p><h4 id=\"heading-12\">1.2 ë°ì´í„° ì •ê·œí™”</h4>\n<pre><code class=\"language-python\">def normalize_features(data):\n    scaler = MinMaxScaler()\n    normalized_data = scaler.fit_transform(data)\n    return normalized_data, scaler\n</code></pre>\n<h3 id=\"heading-13\">2. ëª¨ë¸ í•™ìŠµ</h3>\n<h4 id=\"heading-14\">2.1 LSTM í•™ìŠµ í”„ë¡œì„¸ìŠ¤</h4>\n<pre><code class=\"language-python\">def train_lstm_model(model, train_loader, val_loader, epochs):\n    optimizer = optim.Adam(model.parameters())\n    criterion = nn.MSELoss()\n\n<pre><code>for epoch in range(epochs):\n    model.train()\n    for batch_X, batch_y in train_loader:\n        optimizer.zero_grad()\n        outputs = model(batch_X)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n\n    # ê²€ì¦\n    model.eval()\n    val_loss = validate_model(model, val_loader, criterion)\n    print(f'Epoch {epoch}: Val Loss = {val_loss:.4f}')\n</code></pre>\n</code><p><code class=\"language-python\"></code></p></pre><p></p><h4 id=\"heading-15\">2.2 ì•™ìƒë¸” ëª¨ë¸ í†µí•©</h4>\n<pre><code class=\"language-python\">def ensemble_predict(models, weights, X):\n    predictions = []\n    for model_name, model in models.items():\n        pred = model.predict(X)\n        predictions.append(pred * weights[model_name])\n    return np.sum(predictions, axis=0)\n</code></pre>\n<h2 id=\"heading-16\">ğŸ“ˆ ì„±ëŠ¥ í‰ê°€</h2>\n<h3 id=\"heading-17\">1. í‰ê°€ ë©”íŠ¸ë¦­</h3>\n<h4 id=\"heading-18\">1.1 ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€</h4>\n<pre><code class=\"language-python\">def evaluate_predictions(y_true, y_pred):\n    metrics = {\n        'mse': mean_squared_error(y_true, y_pred),\n        'mae': mean_absolute_error(y_true, y_pred),\n        'r2': r2_score(y_true, y_pred),\n        'mape': mean_absolute_percentage_error(y_true, y_pred)\n    }\n    return metrics\n</code></pre>\n<h4 id=\"heading-19\">1.2 ë°±í…ŒìŠ¤íŒ…</h4>\n<pre><code class=\"language-python\">def backtest_strategy(model, historical_data, initial_capital=10000):\n    portfolio = Portfolio(initial_capital)\n    signals = generate_trading_signals(model, historical_data)\n\n<pre><code>for timestamp, signal in signals.items():\n    if signal &gt; 0:\n        portfolio.long_position(timestamp)\n    elif signal &amp;#x3C; 0:\n        portfolio.short_position(timestamp)\n\nreturn portfolio.calculate_returns()\n</code></pre>\n</code><p><code class=\"language-python\"></code></p></pre><p></p><h2 id=\"heading-20\">ğŸ” ë¦¬ìŠ¤í¬ ê´€ë¦¬</h2>\n<h3 id=\"heading-21\">1. ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§</h3>\n<h4 id=\"heading-22\">1.1 Value at Risk (VaR) ê³„ì‚°</h4>\n<pre><code class=\"language-python\">def calculate_var(returns, confidence_level=0.95):\n    return np.percentile(returns, (1 - confidence_level) * 100)\n</code></pre>\n<h4 id=\"heading-23\">1.2 Expected Shortfall</h4>\n<pre><code class=\"language-python\">def calculate_expected_shortfall(returns, var):\n    return returns[returns &lt;= var].mean()\n</code></pre>\n<h3 id=\"heading-24\">2. í¬ì§€ì…˜ ì‚¬ì´ì§•</h3>\n<pre><code class=\"language-python\">def calculate_position_size(prediction, confidence, account_size):\n    base_size = account_size * 0.02  # 2% ë¦¬ìŠ¤í¬ ë£°\n    adjusted_size = base_size * confidence\n    return min(adjusted_size, account_size * 0.05)  # ìµœëŒ€ 5% ì œí•œ\n</code></pre>\n<h2 id=\"heading-25\">ğŸš€ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§</h2>\n<h3 id=\"heading-26\">1. ëª¨ë¸ ì„œë¹™</h3>\n<h4 id=\"heading-27\">1.1 ëª¨ë¸ ì§ë ¬í™”</h4>\n<pre><code class=\"language-python\">def save_model(model, path):\n    torch.save({\n        'model_state_dict': model.state_dict(),\n        'hyperparameters': model.hyperparameters,\n        'scaler': model.scaler\n    }, path)\n</code></pre>\n<h4 id=\"heading-28\">1.2 ì‹¤ì‹œê°„ ì¶”ë¡ </h4>\n<pre><code class=\"language-python\">@app.route('/predict', methods=['POST'])\ndef predict():\n    data = request.json\n    prediction = model.predict(preprocess_data(data))\n    confidence = calculate_prediction_confidence(prediction)\n    return jsonify({\n        'prediction': prediction,\n        'confidence': confidence\n    })\n</code></pre>\n<h3 id=\"heading-29\">2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§</h3>\n<pre><code class=\"language-python\">def monitor_model_performance(predictions, actuals):\n    metrics = calculate_metrics(predictions, actuals)\n    alert_if_degraded(metrics)\n    log_performance(metrics)\n</code></pre>\n<p>ì´ ë¬¸ì„œëŠ” ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì„¤ê³„ ë° êµ¬í˜„ ìƒì„¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì§€ì†ì ìœ¼ë¡œ ê°œì„ ë˜ë©°, ì„±ëŠ¥ ë©”íŠ¸ë¦­ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµë„ í•¨ê»˜ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤. ğŸš€</p>\n",
      "tocItems": [
        {
          "id": "heading-0",
          "text": "title: \"Entasis Engine - AI ëª¨ë¸ ì„¤ê³„\"\ndate: \"2025-02-13\"\ncategory: \"projects\"\ndescription: \"ê°€ìƒìì‚° ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œì˜ AI ëª¨ë¸ ì•„í‚¤í…ì²˜ ë° êµ¬í˜„ ìƒì„¸\"\ntags:\n[\n\"ai\",\n\"machine-learning\",\n\"deep-learning\",\n\"lstm\",\n\"ensemble\",\n\"prediction\",\n\"risk-analysis\",\n]\nthumbnail: \"/images/cryptocurrency.jpg\"",
          "level": 2,
          "isMainTopic": true,
          "position": 0
        },
        {
          "id": "heading-1",
          "text": "ê¸ˆìœµ ë°ì´í„° ë¶„ì„ ì‹œìŠ¤í…œ AI ëª¨ë¸ ì„¤ê³„",
          "level": 1,
          "isMainTopic": true,
          "position": 50
        },
        {
          "id": "heading-2",
          "text": "ğŸ“Š ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”",
          "level": 2,
          "isMainTopic": true,
          "position": 100
        },
        {
          "id": "heading-3",
          "text": "1. ì˜ˆì¸¡ ëª¨ë¸ êµ¬ì¡°",
          "level": 3,
          "isMainTopic": false,
          "position": 150
        },
        {
          "id": "heading-4",
          "text": "1.1 LSTM ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡",
          "level": 4,
          "isMainTopic": false,
          "position": 200
        },
        {
          "id": "heading-5",
          "text": "1.2 ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„±",
          "level": 4,
          "isMainTopic": false,
          "position": 250
        },
        {
          "id": "heading-6",
          "text": "2. íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§",
          "level": 3,
          "isMainTopic": false,
          "position": 300
        },
        {
          "id": "heading-7",
          "text": "2.1 ê¸°ìˆ ì  ì§€í‘œ",
          "level": 4,
          "isMainTopic": false,
          "position": 350
        },
        {
          "id": "heading-8",
          "text": "2.2 ì‹œì¥ ê°ì„± ë¶„ì„",
          "level": 4,
          "isMainTopic": false,
          "position": 400
        },
        {
          "id": "heading-9",
          "text": "ğŸ”„ í•™ìŠµ íŒŒì´í”„ë¼ì¸",
          "level": 2,
          "isMainTopic": true,
          "position": 450
        },
        {
          "id": "heading-10",
          "text": "1. ë°ì´í„° ì „ì²˜ë¦¬",
          "level": 3,
          "isMainTopic": false,
          "position": 500
        },
        {
          "id": "heading-11",
          "text": "1.1 ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„",
          "level": 4,
          "isMainTopic": false,
          "position": 550
        },
        {
          "id": "heading-12",
          "text": "1.2 ë°ì´í„° ì •ê·œí™”",
          "level": 4,
          "isMainTopic": false,
          "position": 600
        },
        {
          "id": "heading-13",
          "text": "2. ëª¨ë¸ í•™ìŠµ",
          "level": 3,
          "isMainTopic": false,
          "position": 650
        },
        {
          "id": "heading-14",
          "text": "2.1 LSTM í•™ìŠµ í”„ë¡œì„¸ìŠ¤",
          "level": 4,
          "isMainTopic": false,
          "position": 700
        },
        {
          "id": "heading-15",
          "text": "2.2 ì•™ìƒë¸” ëª¨ë¸ í†µí•©",
          "level": 4,
          "isMainTopic": false,
          "position": 750
        },
        {
          "id": "heading-16",
          "text": "ğŸ“ˆ ì„±ëŠ¥ í‰ê°€",
          "level": 2,
          "isMainTopic": true,
          "position": 800
        },
        {
          "id": "heading-17",
          "text": "1. í‰ê°€ ë©”íŠ¸ë¦­",
          "level": 3,
          "isMainTopic": false,
          "position": 850
        },
        {
          "id": "heading-18",
          "text": "1.1 ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€",
          "level": 4,
          "isMainTopic": false,
          "position": 900
        },
        {
          "id": "heading-19",
          "text": "1.2 ë°±í…ŒìŠ¤íŒ…",
          "level": 4,
          "isMainTopic": false,
          "position": 950
        },
        {
          "id": "heading-20",
          "text": "ğŸ” ë¦¬ìŠ¤í¬ ê´€ë¦¬",
          "level": 2,
          "isMainTopic": true,
          "position": 1000
        },
        {
          "id": "heading-21",
          "text": "1. ë¦¬ìŠ¤í¬ ëª¨ë‹ˆí„°ë§",
          "level": 3,
          "isMainTopic": false,
          "position": 1050
        },
        {
          "id": "heading-22",
          "text": "1.1 Value at Risk (VaR) ê³„ì‚°",
          "level": 4,
          "isMainTopic": false,
          "position": 1100
        },
        {
          "id": "heading-23",
          "text": "1.2 Expected Shortfall",
          "level": 4,
          "isMainTopic": false,
          "position": 1150
        },
        {
          "id": "heading-24",
          "text": "2. í¬ì§€ì…˜ ì‚¬ì´ì§•",
          "level": 3,
          "isMainTopic": false,
          "position": 1200
        },
        {
          "id": "heading-25",
          "text": "ğŸš€ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§",
          "level": 2,
          "isMainTopic": true,
          "position": 1250
        },
        {
          "id": "heading-26",
          "text": "1. ëª¨ë¸ ì„œë¹™",
          "level": 3,
          "isMainTopic": false,
          "position": 1300
        },
        {
          "id": "heading-27",
          "text": "1.1 ëª¨ë¸ ì§ë ¬í™”",
          "level": 4,
          "isMainTopic": false,
          "position": 1350
        },
        {
          "id": "heading-28",
          "text": "1.2 ì‹¤ì‹œê°„ ì¶”ë¡ ",
          "level": 4,
          "isMainTopic": false,
          "position": 1400
        },
        {
          "id": "heading-29",
          "text": "2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§",
          "level": 3,
          "isMainTopic": false,
          "position": 1450
        }
      ]
    },
    "en": {
      "title": "Entasis Engine - AI Model Design",
      "description": "AI model architecture and implementation details for digital asset data analysis system",
      "content": "<hr>\n<h2 id=\"heading-0\">title: \"Entasis Engine - AI Model Design\"\ndate: \"2025-02-13\"\ncategory: \"projects\"\ndescription: \"AI model architecture and implementation details for digital asset data analysis system\"\ntags:\n[\n\"ai\",\n\"machine-learning\",\n\"deep-learning\",\n\"lstm\",\n\"ensemble\",\n\"prediction\",\n\"risk-analysis\",\n]\nthumbnail: \"/images/cryptocurrency.jpg\"</h2>\n<h1 id=\"heading-1\">Financial Data Analysis System AI Model Design</h1>\n<h2 id=\"heading-2\">ğŸ“Š Model Architecture Overview</h2>\n<h3 id=\"heading-3\">1. Prediction Model Structure</h3>\n<h4 id=\"heading-4\">1.1 LSTM-based Time Series Prediction</h4>\n",
      "tocItems": [
        {
          "id": "heading-0",
          "text": "title: \"Entasis Engine - AI Model Design\"\ndate: \"2025-02-13\"\ncategory: \"projects\"\ndescription: \"AI model architecture and implementation details for digital asset data analysis system\"\ntags:\n[\n\"ai\",\n\"machine-learning\",\n\"deep-learning\",\n\"lstm\",\n\"ensemble\",\n\"prediction\",\n\"risk-analysis\",\n]\nthumbnail: \"/images/cryptocurrency.jpg\"",
          "level": 2,
          "isMainTopic": true,
          "position": 0
        },
        {
          "id": "heading-1",
          "text": "Financial Data Analysis System AI Model Design",
          "level": 1,
          "isMainTopic": true,
          "position": 50
        },
        {
          "id": "heading-2",
          "text": "ğŸ“Š Model Architecture Overview",
          "level": 2,
          "isMainTopic": true,
          "position": 100
        },
        {
          "id": "heading-3",
          "text": "1. Prediction Model Structure",
          "level": 3,
          "isMainTopic": false,
          "position": 150
        },
        {
          "id": "heading-4",
          "text": "1.1 LSTM-based Time Series Prediction",
          "level": 4,
          "isMainTopic": false,
          "position": 200
        }
      ]
    }
  },
  "imageHeights": {}
}